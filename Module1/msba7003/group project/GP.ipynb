{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用pym3包 （没安装上）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pip install pymc3\n",
    "pip install arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m n_customers \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Define the model\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mpm\u001B[49m\u001B[38;5;241m.\u001B[39mModel() \u001B[38;5;28;01mas\u001B[39;00m model:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;66;03m# Priors\u001B[39;00m\n\u001B[1;32m     11\u001B[0m     std_dev_idx \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mCategorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd_dev_idx\u001B[39m\u001B[38;5;124m'\u001B[39m, p\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mones(\u001B[38;5;28mlen\u001B[39m(possible_std_devs))\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(possible_std_devs), shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(sku_costs))\n\u001B[1;32m     12\u001B[0m     std_devs \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mDeterministic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd_devs\u001B[39m\u001B[38;5;124m'\u001B[39m, possible_std_devs[std_dev_idx])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pm' is not defined"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.5, 1, 2, 3, 4])\n",
    "n_customers = 100\n",
    "\n",
    "# Define the model\n",
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    std_dev_idx = pm.Categorical('std_dev_idx', p=np.ones(len(possible_std_devs))/len(possible_std_devs), shape=len(sku_costs))\n",
    "    std_devs = pm.Deterministic('std_devs', possible_std_devs[std_dev_idx])\n",
    "\n",
    "    # Likelihood\n",
    "    for i in range(len(sku_costs)):\n",
    "        pm.Normal('wtp_{}'.format(i), mu=wtp_means[i], sd=std_devs[i], observed=np.repeat(sku_costs[i], purchases[i]))\n",
    "    \n",
    "    # Posterior\n",
    "    trace = pm.sample(5000, return_inferencedata=True)\n",
    "\n",
    "# Summarize the results\n",
    "az.summary(trace, var_names=['std_dev_idx'])\n",
    "az.plot_posterior(trace, var_names=['std_dev_idx'], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只用numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU 1 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[9.99979402e-01 2.05983321e-05 3.47866003e-13 5.93829611e-17\n",
      " 4.35867028e-19]\n",
      "SKU 2 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[5.97178189e-15 9.40138734e-01 5.94067109e-02 4.38341034e-04\n",
      " 1.62137305e-05]\n",
      "SKU 3 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[6.29882586e-08 9.99964599e-01 3.53284167e-05 9.80957146e-09\n",
      " 5.56791812e-11]\n",
      "SKU 4 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[4.36343401e-04 9.99562379e-01 1.27804087e-06 5.44581780e-11\n",
      " 9.37645756e-14]\n",
      "SKU 5 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[9.63004253e-08 9.99894911e-01 1.04884251e-04 1.06729163e-07\n",
      " 1.49117667e-09]\n",
      "SKU 6 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[9.99999857e-01 1.43491900e-07 2.25720102e-12 3.36533719e-14\n",
      " 3.71417857e-15]\n",
      "SKU 7 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[7.28178398e-10 9.99872561e-01 1.27417084e-04 2.10490913e-08\n",
      " 6.99394004e-11]\n",
      "SKU 8 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[1.67830622e-11 9.62164064e-01 3.71390593e-02 6.49906457e-04\n",
      " 4.69706987e-05]\n",
      "SKU 9 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[1.44150298e-84 4.02181418e-17 4.20563868e-01 5.63646839e-01\n",
      " 1.57892927e-02]\n",
      "SKU 10 posterior probabilities for std deviations [0.5 1.  2.  3.  4. ]:\n",
      "[1.29875978e-15 9.78075396e-01 2.18813003e-02 4.26763153e-05\n",
      " 6.27722122e-07]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.5, 1, 2, 3, 4])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "# Function to compute likelihood\n",
    "def compute_likelihood(sku_index, std_dev):\n",
    "    mean = wtp_means[sku_index]\n",
    "    cost = sku_costs[sku_index]\n",
    "    purchase_count = purchases[sku_index]\n",
    "    \n",
    "    # Probability of purchase\n",
    "    prob_purchase = norm.cdf(cost, loc=mean, scale=std_dev)\n",
    "    \n",
    "    # Likelihood of observing the purchase count\n",
    "    likelihood = (prob_purchase ** purchase_count) * ((1 - prob_purchase) ** (n_customers - purchase_count))\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "# Calculate the posterior probabilities\n",
    "posterior_probs = np.zeros((len(sku_costs), len(possible_std_devs)))\n",
    "\n",
    "for i in range(len(sku_costs)):\n",
    "    likelihoods = np.array([compute_likelihood(i, std_dev) for std_dev in possible_std_devs])\n",
    "    marginal_likelihood = np.sum(likelihoods * prior_prob)\n",
    "    posterior_probs[i] = (likelihoods * prior_prob) / marginal_likelihood\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for i in range(len(sku_costs)):\n",
    "    print(f'SKU {i + 1} posterior probabilities for std deviations {possible_std_devs}:')\n",
    "    print(posterior_probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU 1 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[1.50866018e-09 9.96353882e-01 3.62559254e-03 2.05236509e-05\n",
      " 4.81630813e-10 3.46604782e-13]\n",
      "SKU 2 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[1.16197564e-125 3.00382705e-015 6.82016013e-003 4.72893052e-001\n",
      " 4.90405006e-001 2.98817822e-002]\n",
      "SKU 3 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[4.43622096e-73 4.42127792e-08 2.91498950e-01 7.01896115e-01\n",
      " 6.58009336e-03 2.47977563e-05]\n",
      "SKU 4 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[1.22847809e-40 1.54871013e-04 6.44602538e-01 3.54773871e-01\n",
      " 4.68265596e-04 4.53614018e-07]\n",
      "SKU 5 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[8.41157233e-77 6.28955975e-08 3.38202933e-01 6.53049949e-01\n",
      " 8.67855278e-03 6.85018537e-05]\n",
      "SKU 6 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[9.99991874e-01 8.12542821e-06 1.27802577e-10 1.16593330e-12\n",
      " 9.44645200e-16 1.83407274e-17]\n",
      "SKU 7 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[3.72230822e-82 6.33680085e-10 1.02352742e-01 8.70115526e-01\n",
      " 2.74208497e-02 1.10881714e-04]\n",
      "SKU 8 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[5.77398812e-104 1.10892833e-011 3.95707165e-002 6.35742737e-001\n",
      " 3.00147190e-001 2.45393568e-002]\n",
      "SKU 9 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[0.00000000e+00 3.42606373e-84 1.01810915e-29 9.55876738e-17\n",
      " 4.33138130e-04 9.99566862e-01]\n",
      "SKU 10 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5 2. ]:\n",
      "[2.29056069e-127 7.33441397e-016 5.54779604e-003 5.52343085e-001\n",
      " 4.29752214e-001 1.23569051e-002]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1, 1.5, 2])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "# Function to compute likelihood\n",
    "def compute_likelihood(sku_index, std_dev):\n",
    "    mean = wtp_means[sku_index]\n",
    "    cost = sku_costs[sku_index]\n",
    "    purchase_count = purchases[sku_index]\n",
    "    \n",
    "    # Probability of purchase\n",
    "    prob_purchase = norm.cdf(cost, loc=mean, scale=std_dev)\n",
    "    \n",
    "    # Likelihood of observing the purchase count\n",
    "    likelihood = (prob_purchase ** purchase_count) * ((1 - prob_purchase) ** (n_customers - purchase_count))\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "# Calculate the posterior probabilities\n",
    "posterior_probs = np.zeros((len(sku_costs), len(possible_std_devs)))\n",
    "\n",
    "for i in range(len(sku_costs)):\n",
    "    likelihoods = np.array([compute_likelihood(i, std_dev) for std_dev in possible_std_devs])\n",
    "    marginal_likelihood = np.sum(likelihoods * prior_prob)\n",
    "    posterior_probs[i] = (likelihoods * prior_prob) / marginal_likelihood\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for i in range(len(sku_costs)):\n",
    "    print(f'SKU {i + 1} posterior probabilities for std deviations {possible_std_devs}:')\n",
    "    print(posterior_probs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50866018e-009, 9.96353882e-001, 3.62559254e-003,\n",
       "        2.05236509e-005, 4.81630813e-010, 3.46604782e-013],\n",
       "       [1.16197564e-125, 3.00382705e-015, 6.82016013e-003,\n",
       "        4.72893052e-001, 4.90405006e-001, 2.98817822e-002],\n",
       "       [4.43622096e-073, 4.42127792e-008, 2.91498950e-001,\n",
       "        7.01896115e-001, 6.58009336e-003, 2.47977563e-005],\n",
       "       [1.22847809e-040, 1.54871013e-004, 6.44602538e-001,\n",
       "        3.54773871e-001, 4.68265596e-004, 4.53614018e-007],\n",
       "       [8.41157233e-077, 6.28955975e-008, 3.38202933e-001,\n",
       "        6.53049949e-001, 8.67855278e-003, 6.85018537e-005],\n",
       "       [9.99991874e-001, 8.12542821e-006, 1.27802577e-010,\n",
       "        1.16593330e-012, 9.44645200e-016, 1.83407274e-017],\n",
       "       [3.72230822e-082, 6.33680085e-010, 1.02352742e-001,\n",
       "        8.70115526e-001, 2.74208497e-002, 1.10881714e-004],\n",
       "       [5.77398812e-104, 1.10892833e-011, 3.95707165e-002,\n",
       "        6.35742737e-001, 3.00147190e-001, 2.45393568e-002],\n",
       "       [0.00000000e+000, 3.42606373e-084, 1.01810915e-029,\n",
       "        9.55876738e-017, 4.33138130e-004, 9.99566862e-001],\n",
       "       [2.29056069e-127, 7.33441397e-016, 5.54779604e-003,\n",
       "        5.52343085e-001, 4.29752214e-001, 1.23569051e-002]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('posterior_probs.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # 遍历数组的每一行\n",
    "    for row in posterior_probs:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改likelihood 加上value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multinomial\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1.0, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "# Function to compute the value distributions for each SKU\n",
    "def compute_value_distributions(std_dev):\n",
    "    values = np.zeros((n_customers, len(sku_costs)))\n",
    "    for i in range(len(sku_costs)):\n",
    "        mean = wtp_means[i]\n",
    "        cost = sku_costs[i]\n",
    "        values[:, i] = np.random.normal(loc=mean, scale=std_dev, size=n_customers) - cost\n",
    "    return values\n",
    "\n",
    "# Calculate the posterior probabilities\n",
    "posterior_probs = np.zeros(len(possible_std_devs))\n",
    "\n",
    "for std_dev in possible_std_devs:\n",
    "    # Simulate value distributions\n",
    "    values = compute_value_distributions(std_dev)\n",
    "    \n",
    "    # Determine purchases based on highest value\n",
    "    chosen_skus = np.argmax(values, axis=1)\n",
    "    \n",
    "    # Count purchases for each SKU\n",
    "    simulated_purchases = np.array([np.sum(chosen_skus == i) for i in range(len(sku_costs))])\n",
    "    \n",
    "    # Compute the likelihood using multinomial distribution\n",
    "    likelihood = multinomial.pmf(purchases, n_customers, simulated_purchases / n_customers)\n",
    "    posterior_probs[np.where(possible_std_devs == std_dev)[0][0]] = likelihood * prior_prob\n",
    "\n",
    "# Normalize posterior probabilities\n",
    "posterior_probs /= np.sum(posterior_probs)\n",
    "\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for i in range(len(sku_costs)):\n",
    "    print(f'SKU {i + 1} posterior probabilities for std deviations {possible_std_devs}:')\n",
    "    print(posterior_probs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改value的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38410074,  1.70234837,  2.68439468, -1.5400381 ,  2.52735446,\n",
       "        2.17907195,  5.32500532,  0.87184591,  2.61871114,  2.98893728,\n",
       "       -1.49591934, -3.01613455, -1.8982282 ,  1.95926087,  1.13633625,\n",
       "       -1.3049979 ,  2.36641933,  0.12760218,  4.24319443,  1.59225153,\n",
       "        0.67280701,  1.7406106 ,  0.47208346, -2.27000493,  1.10735246,\n",
       "       -1.29725284, -0.29354872,  1.90717908,  2.91256866,  5.91003855,\n",
       "        0.01563035, -2.4259523 ,  3.7400363 ,  2.22053615,  3.60589823,\n",
       "        3.97455969, -1.4036015 ,  1.29904422,  1.175483  ,  1.94945698,\n",
       "        2.44970134,  2.7222264 ,  0.50060515, -2.38948952, -1.23808979,\n",
       "        4.94876247,  2.22776273,  3.2114538 ,  1.49826768,  1.11698592,\n",
       "        2.51358381, -1.15380742,  0.45876858,  0.69878144,  2.87782133,\n",
       "        1.6779635 ,  1.86100306, -0.02729564,  0.83384496,  1.98886972,\n",
       "       -0.33455776,  1.88917774,  3.79700104,  2.79587995,  1.75245683,\n",
       "        3.06237317,  0.20581099, -1.693547  ,  3.11150992,  4.56337172,\n",
       "        0.84024648,  1.69483432,  1.29862288, -0.25701113,  3.37089988,\n",
       "        5.33718923,  1.52960667,  2.66393619,  1.84801045, -1.18062451,\n",
       "        5.19148894,  1.27682344,  2.7691844 , -3.23057106,  1.22568352,\n",
       "       -2.48097799,  2.51816558,  3.72252744,  1.62083112,  2.43324435,\n",
       "        1.76090033,  1.55377266, -0.54601321,  2.85414295, -3.03969071,\n",
       "       -1.2379888 , -1.06153613,  0.33137197,  1.45092166,  4.27814417])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multinomial\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1.0, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs) \n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "def compute_value_distribution_for_sku(sku_index, std_dev):\n",
    "    mean = wtp_means[sku_index]\n",
    "    cost = sku_costs[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std_dev, size=n_customers) - cost\n",
    "    return values\n",
    "\n",
    "\n",
    "compute_value_distribution_for_sku(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU 1 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 2 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 3 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 4 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 5 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 6 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 7 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 8 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 9 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "SKU 10 posterior probabilities for std deviations [0.2 0.5 0.8 1.  1.5]:\n",
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multinomial\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1.0, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "# Function to compute the value distribution for a specific SKU\n",
    "def compute_value_distribution_for_sku(sku_index, std_dev):\n",
    "    mean = wtp_means[sku_index]\n",
    "    cost = sku_costs[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std_dev, size=n_customers) - cost\n",
    "    return values\n",
    "\n",
    "# Function to compute the posterior probabilities\n",
    "def compute_posterior_probabilities():\n",
    "    posterior_probs = np.zeros(len(possible_std_devs))\n",
    "\n",
    "    for std_dev in possible_std_devs:\n",
    "        # Simulate value distributions for all SKUs\n",
    "        values = np.zeros((n_customers, len(sku_costs)))\n",
    "        for i in range(len(sku_costs)):\n",
    "            values[:, i] = compute_value_distribution_for_sku(i, std_dev)\n",
    "        \n",
    "        # Determine purchases based on highest value\n",
    "        chosen_skus = np.argmax(values, axis=1)\n",
    "        \n",
    "        # Count purchases for each SKU\n",
    "        simulated_purchases = np.array([np.sum(chosen_skus == i) for i in range(len(sku_costs))])\n",
    "        \n",
    "        # Ensure probabilities sum to 1 for multinomial distribution\n",
    "        simulated_purchases_prob = simulated_purchases / n_customers\n",
    "        if np.sum(simulated_purchases_prob) != 1:\n",
    "            simulated_purchases_prob = simulated_purchases_prob / np.sum(simulated_purchases_prob)\n",
    "        \n",
    "        # Compute the log-likelihood using multinomial distribution\n",
    "        log_likelihood = multinomial.logpmf(purchases, n_customers, simulated_purchases_prob)\n",
    "        posterior_probs[np.where(possible_std_devs == std_dev)[0][0]] = np.exp(log_likelihood) * prior_prob\n",
    "\n",
    "    # Handle potential zero division\n",
    "    if np.sum(posterior_probs) == 0:\n",
    "        posterior_probs += 1e-10\n",
    "\n",
    "    # Normalize posterior probabilities\n",
    "    posterior_probs /= np.sum(posterior_probs)\n",
    "\n",
    "    return posterior_probs\n",
    "\n",
    "posterior_probs = compute_posterior_probabilities()\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for i in range(len(sku_costs)):\n",
    "    print(f'SKU {i + 1} posterior probabilities for std deviations {possible_std_devs}:')\n",
    "    print(posterior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.73092316,  1.01380521,  1.61573353,  0.57164464,  1.9289302 ,\n",
       "        1.69188893,  1.02100118,  0.89132227,  1.28945834,  1.77010061,\n",
       "        0.8365117 ,  1.7273777 ,  0.80298221,  1.02905957,  1.35359803,\n",
       "        1.52200391,  1.01496679,  1.51951809,  1.73289625,  1.65670547,\n",
       "        1.16015349,  2.02992748,  1.00517377,  2.51602103,  0.61892137,\n",
       "        1.71100529,  1.87743138,  1.69375198,  0.84753024,  1.11514073,\n",
       "        1.235081  ,  1.354096  ,  1.0563788 ,  1.68829896,  1.13631716,\n",
       "        1.02708903,  1.8098185 ,  1.87669125,  2.33390337,  0.43981785,\n",
       "        0.61766651,  1.74187266,  1.91222127,  0.62137895,  1.1458234 ,\n",
       "        1.30749135,  0.50341666,  1.96965701,  2.5111736 ,  0.91080509,\n",
       "        1.93819566,  1.33488739,  1.29649026,  1.13950927,  2.20280032,\n",
       "        1.89469105,  1.72265827,  2.32405612,  2.17768798,  2.31215052,\n",
       "        1.41692571,  1.9360128 ,  1.92769217,  1.06296045,  1.65664077,\n",
       "        1.54775626,  1.88604291,  1.890036  ,  1.42874061,  0.80804423,\n",
       "        1.1184583 ,  1.52992212,  1.27594597, -0.06413083,  1.46297836,\n",
       "        1.33669785,  1.5729803 ,  1.97741328,  1.66712503,  0.8422023 ,\n",
       "        1.22899082,  2.20019437,  1.6988797 ,  1.24564   ,  1.23386687,\n",
       "        1.43907597,  0.91293304,  1.36719258,  0.92225255,  0.99236005,\n",
       "        1.72145327,  1.28183771,  1.04952583,  0.63474563,  0.52357369,\n",
       "        1.04085   ,  0.78426932,  1.46578143,  1.95874388,  1.87905171])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_value_distribution_for_sku(2,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from itertools import product\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "initial_price = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "\n",
    "# Function to compute the value distribution for a specific SKU\n",
    "def compute_value_distribution_for_sku(sku_index, std_dev):\n",
    "    mean = wtp_means[sku_index]\n",
    "    cost = sku_costs[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std_dev, size=n_customers) - initial_price\n",
    "    return values\n",
    "\n",
    "# Function to compute the posterior probabilities\n",
    "def compute_posterior_probabilities():\n",
    "    # Generate all possible standard deviation combinations for all SKUs\n",
    "    std_dev_combinations = list(product(possible_std_devs, repeat=len(sku_costs)))\n",
    "    \n",
    "    posterior_probs = np.zeros((len(sku_costs), len(possible_std_devs)))\n",
    "\n",
    "    for idx, std_dev_comb in enumerate(std_dev_combinations):\n",
    "        # Simulate value distributions for all SKUs based on the current std_dev_comb\n",
    "        values = np.zeros((n_customers, len(sku_costs)))\n",
    "        for i in range(len(sku_costs)):\n",
    "            values[:, i] = compute_value_distribution_for_sku(i, std_dev_comb[i])\n",
    "        \n",
    "        # Determine purchases based on highest value\n",
    "        chosen_skus = np.argmax(values, axis=1)\n",
    "        \n",
    "        # Count purchases for each SKU\n",
    "        simulated_purchases = np.array([np.sum(chosen_skus == i) for i in range(len(sku_costs))])\n",
    "        \n",
    "        # Ensure probabilities sum to 1 for multinomial distribution\n",
    "        simulated_purchases_prob = simulated_purchases / n_customers\n",
    "        if np.sum(simulated_purchases_prob) != 1:\n",
    "            simulated_purchases_prob = simulated_purchases_prob / np.sum(simulated_purchases_prob)\n",
    "        \n",
    "        # Compute the log-likelihood using multinomial distribution\n",
    "            log_likelihood = multinomial.logpmf([simulated_purchases, n_customers - simulated_purchases], n_customers, [simulated_purchases_prob, 1 - simulated_purchases_prob])\n",
    "            posterior_probs[idx, std_dev_comb] = np.exp(log_likelihood) * prior_prob\n",
    "\n",
    "        # Normalize posterior probabilities for the current SKU\n",
    "        posterior_probs[idx, :] /= np.sum(posterior_probs[idx, :])\n",
    "\n",
    "        return posterior_probs\n",
    "\n",
    "\n",
    "compute_posterior_probabilities()\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for i in range(len(sku_costs)):\n",
    "    print(f'SKU {i + 1} posterior probabilities for std deviations {possible_std_devs}:')\n",
    "    print(posterior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增加顾客不购买的情况，更改likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from itertools import product\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "initial_price = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "purchases = np.append(purchases, n_customers - purchases.sum())\n",
    "\n",
    "# Function to compute the value distribution for a specific SKU\n",
    "def compute_value_distribution_for_sku(sku_index, std):\n",
    "    mean = wtp_means[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std, size=n_customers) - initial_price[sku_index]\n",
    "    return values\n",
    "\n",
    "# Generate all possible standard deviation combinations for all SKUs\n",
    "std_dev_combinations = list(product(possible_std_devs, repeat=len(sku_costs)))\n",
    "\n",
    "posterior_probs = {sku_idx: np.zeros(len(possible_std_devs)) for sku_idx in range(len(sku_costs)+1)}\n",
    "\n",
    "\n",
    "for idx, std_dev_comb in enumerate(std_dev_combinations):\n",
    "    # Simulate value distributions for all SKUs based on the current std_dev_comb\n",
    "    values = np.zeros((n_customers, len(sku_costs)))\n",
    "    for i in range(len(sku_costs)):\n",
    "        values[:, i] = compute_value_distribution_for_sku(i, std_dev_comb[i])\n",
    "            \n",
    "    # Determine purchases based on highest value\n",
    "    max_values = np.max(values, axis=1)\n",
    "\n",
    "    # Count purchases for each SKU\n",
    "    chosen_skus = np.full(values.shape[0], -1, dtype=int)\n",
    "    simulated_purchases = np.zeros(len(sku_costs) + 1)\n",
    "    # 只有当最大 value 大于 0 时，顾客才会购买\n",
    "    for i in range(values.shape[0]):\n",
    "        if max_values[i] > 0:\n",
    "            sku_idx = np.argmax(values[i, :])\n",
    "            chosen_skus[i] = sku_idx\n",
    "            simulated_purchases[sku_idx] += 1\n",
    "        else:\n",
    "            simulated_purchases[-1] += 1\n",
    "                    \n",
    "    # Ensure probabilities sum to 1 for multinomial distribution\n",
    "    simulated_purchases_prob = simulated_purchases / n_customers\n",
    "            \n",
    "    # Compute the likelihood using multinomial distribution\n",
    "    # log_likelihood = multinomial.logpmf(purchases, n_customers, simulated_purchases_prob)\n",
    "    # posterior = np.exp(log_likelihood) * prior_prob\n",
    "\n",
    "    # marginal\n",
    "    for sku_idx in range(len(sku_costs)):\n",
    "        other_std_devs = [std_dev_comb[i] for i in range(len(sku_costs)) if i != sku_idx]\n",
    "        marginal_likelihood = np.sum([multinomial.logpmf(purchases, n_customers, simulated_purchases_prob) for _ in other_std_devs])\n",
    "        posterior_probs[sku_idx][idx] = np.exp(marginal_likelihood) * prior_prob\n",
    "\n",
    "    # Normalize posterior probabilities for the current SKU\n",
    "    for sku_idx in range(len(sku_costs)):\n",
    "        posterior_probs[sku_idx] /= posterior_probs[sku_idx].sum()\n",
    "\n",
    "\n",
    "# Print the posterior probabilities\n",
    "for sku_idx in range(len(sku_costs)):\n",
    "    print(f\"SKU {sku_idx} 的后验概率:\", posterior_probs[sku_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from itertools import product\n",
    "\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "initial_price = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.2, 0.5, 0.8, 1, 1.5])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "purchases = np.append(purchases, n_customers - purchases.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the value distribution for a specific SKU\n",
    "def compute_value_distribution_for_sku(sku_index, std):\n",
    "    mean = wtp_means[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std, size=n_customers) - initial_price[sku_index]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible standard deviation combinations for all SKUs\n",
    "std_dev_combinations = list(product(possible_std_devs, repeat=len(sku_costs)))\n",
    "\n",
    "# Initialize the posterior array\n",
    "posterior = np.zeros((len(std_dev_combinations)),len(sku_costs)+1)\n",
    "\n",
    "for idx, std_dev_comb in enumerate(std_dev_combinations):\n",
    "        \n",
    "    # Simulate value distributions for all SKUs based on the current std_dev_comb\n",
    "    values = np.zeros((n_customers, len(sku_costs)))\n",
    "    for i in range(len(sku_costs)):\n",
    "        values[:, i] = compute_value_distribution_for_sku(i, std_dev_comb[i])\n",
    "                \n",
    "    # Determine purchases based on highest value\n",
    "    max_values = np.max(values, axis=1)\n",
    "\n",
    "    # Count purchases for each SKU\n",
    "    chosen_skus = np.full(values.shape[0], -1, dtype=int)\n",
    "    simulated_purchases = np.zeros(len(sku_costs) + 1)\n",
    "    # 只有当最大 value 大于 0 时，顾客才会购买\n",
    "    for i in range(values.shape[0]):\n",
    "        if max_values[i] > 0:\n",
    "            sku_idx = np.argmax(values[i, :])\n",
    "            chosen_skus[i] = sku_idx\n",
    "            simulated_purchases[sku_idx] += 1\n",
    "        else:\n",
    "            simulated_purchases[-1] += 1\n",
    "                        \n",
    "    # Ensure probabilities sum to 1 for multinomial distribution\n",
    "    simulated_purchases_prob = simulated_purchases / n_customers\n",
    "                \n",
    "    # Compute the likelihood using multinomial distribution\n",
    "    log_likelihood = multinomial.logpmf(purchases, n_customers, simulated_purchases_prob)\n",
    "    unnormalized_posterior = np.exp(log_likelihood) * prior_prob\n",
    "    posterior[idx, :] = unnormalized_posterior / unnormalized_posterior.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the marginal posterior array\n",
    "marginal_posterior = np.zeros((len(sku_costs)+1, len(possible_std_devs)))\n",
    "\n",
    "# Calculate the marginal posterior probabilities for each SKU\n",
    "for sku_idx in range(len(sku_costs)+1):\n",
    "    for std_dev_idx, std_dev in enumerate(possible_std_devs):\n",
    "        # Sum over all combinations where the current SKU has the current std_dev\n",
    "        marginal_posterior[sku_idx, std_dev_idx] = np.sum(posterior[:, sku_idx][std_dev_combinations[:, sku_idx] == std_dev])\n",
    "\n",
    "# Normalize the marginal posterior probabilities for each SKU\n",
    "marginal_posterior /= np.sum(marginal_posterior, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.08504999999999999)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import multinomial\n",
    "\n",
    "# 定义参数\n",
    "x = [2, 3, 5]  # 观测到的事件次数\n",
    "n = 10         # 试验总次数\n",
    "p = [0.2, 0.3, 0.5]  # 每个类别的概率\n",
    "\n",
    "# 计算对数概率质量函数\n",
    "log_pmf = multinomial.logpmf(x, n, p)\n",
    "\n",
    "likelihood = np.exp(log_pmf)\n",
    "likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_prob = np.array([0.1, 0.4, 0.5])\n",
    "unnormalized_posterior = likelihood * prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.4, 0.5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnormalized_posterior / unnormalized_posterior.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# margin likelihood"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:57:24.718074Z",
     "start_time": "2024-09-25T10:57:24.304032Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multinomial\n",
    "from itertools import product\n",
    "np.random.seed(0)\n",
    "# Given data\n",
    "sku_costs = np.array([5, 6, 7, 8, 6, 2, 8, 5, 15, 7])\n",
    "wtp_means = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "initial_price = np.array([6, 7.2, 8.4, 9.6, 7.2, 2.4, 9.6, 6, 18, 8.4])\n",
    "purchases = np.array([2, 16, 7, 3, 10, 4, 6, 19, 11, 12])\n",
    "possible_std_devs = np.array([0.5, 1, 2])\n",
    "prior_prob = 1 / len(possible_std_devs)  # Each standard deviation is equally likely\n",
    "\n",
    "# Number of customers\n",
    "n_customers = 100\n",
    "purchases = np.append(purchases, n_customers - purchases.sum())\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:57:24.792448Z",
     "start_time": "2024-09-25T10:57:24.789993Z"
    }
   },
   "source": [
    "# Function to compute the value distribution for a specific SKU\n",
    "def compute_value_distribution_for_sku(sku_index, std):\n",
    "    mean = wtp_means[sku_index]\n",
    "    values = np.random.normal(loc=mean, scale=std, size=n_customers) - initial_price[sku_index]\n",
    "    return values"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:57:25.666591Z",
     "start_time": "2024-09-25T10:57:25.630607Z"
    }
   },
   "source": [
    "# Generate all possible standard deviation combinations for all SKUs\n",
    "std_dev_combinations = list(product(possible_std_devs, repeat=len(sku_costs)))\n",
    "\n",
    "# Initialize the posterior array\n",
    "likelihood = np.zeros((len(std_dev_combinations)))\n",
    "\n",
    "for idx, std_dev_comb in enumerate(std_dev_combinations):\n",
    "        \n",
    "    # Simulate value distributions for all SKUs based on the current std_dev_comb\n",
    "    values = np.zeros((n_customers, len(sku_costs)))\n",
    "    for i in range(len(sku_costs)):\n",
    "        values[:, i] = compute_value_distribution_for_sku(i, std_dev_comb[i])\n",
    "                \n",
    "    # Determine purchases based on highest value\n",
    "    max_values = np.max(values, axis=1)\n",
    "\n",
    "    # Count purchases for each SKU\n",
    "    chosen_skus = np.full(values.shape[0], -1, dtype=int)\n",
    "    simulated_purchases = np.zeros(len(sku_costs) + 1)\n",
    "    # 只有当最大 value 大于 0 时，顾客才会购买\n",
    "    for i in range(values.shape[0]):\n",
    "        if max_values[i] > 0:\n",
    "            sku_idx = np.argmax(values[i, :])\n",
    "            chosen_skus[i] = sku_idx\n",
    "            simulated_purchases[sku_idx] += 1\n",
    "        else:\n",
    "            simulated_purchases[-1] += 1\n",
    "                        \n",
    "    # Ensure probabilities sum to 1 for multinomial distribution\n",
    "    simulated_purchases_prob = simulated_purchases / n_customers\n",
    "\n",
    "    # Ensure probabilities sum to 1 for multinomial distribution\n",
    "    # epsilon = 1e-10\n",
    "    # simulated_purchases_prob = (simulated_purchases + epsilon) / (n_customers + epsilon * len(sku_costs))\n",
    "\n",
    "                \n",
    "    # Compute the likelihood using multinomial distribution\n",
    "    log_likelihood = multinomial.logpmf(purchases, n_customers, simulated_purchases_prob)\n",
    "    print(log_likelihood, end='\\t')\n",
    "    likelihood[idx]= np.exp(log_likelihood)\n",
    "    if idx == 100: break\n",
    "    # posterior[idx, :] = unnormalized_posterior / unnormalized_posterior.sum()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-49.7612187950906\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-56.642110584354214\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-62.5768894425978\t-77.88807258166275\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-78.41312704008061\t-67.86613626694657\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t-inf\t"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:51:47.111618Z",
     "start_time": "2024-09-25T10:51:47.108661Z"
    }
   },
   "cell_type": "code",
   "source": "np.isnan(likelihood).sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:51:47.376365Z",
     "start_time": "2024-09-25T10:51:47.112621Z"
    }
   },
   "source": [
    "prior = np.full(len(possible_std_devs), 1 / len(possible_std_devs))\n",
    "\n",
    "# Initialize the marginal likelihood array\n",
    "marginal_likelihood = np.zeros((len(sku_costs)+1, len(possible_std_devs)))\n",
    "marginal_likelihood_sum = np.zeros((len(sku_costs)+1))\n",
    "\n",
    "# Calculate the marginal likelihood for each SKU and each assumption\n",
    "posterior = pd.DataFrame(np.zeros((len(sku_costs)+1, len(possible_std_devs))))\n",
    "for i in range(len(sku_costs) + 1):\n",
    "    for j in range(len(possible_std_devs)):\n",
    "        indices = [idx for idx, comb in enumerate(std_dev_combinations) if comb[i % len(comb)] == possible_std_devs[j]]\n",
    "        marginal_likelihood[i, j] = np.sum(likelihood[indices])\n",
    "    marginal_likelihood_sum[i] = np.sum(marginal_likelihood[i, :] * prior)\n",
    "    posterior.iloc[i,:] = (marginal_likelihood[i,:] * prior_prob) / marginal_likelihood_sum[i]"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T10:51:47.382046Z",
     "start_time": "2024-09-25T10:51:47.376365Z"
    }
   },
   "source": [
    "posterior"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           0         1         2\n",
       "0   0.708938  0.287579  0.003482\n",
       "1   0.000038  0.076618  0.923344\n",
       "2   0.221079  0.703894  0.075027\n",
       "3   0.745596  0.095790  0.158615\n",
       "4   0.002355  0.799730  0.197915\n",
       "5   0.279098  0.714269  0.006633\n",
       "6   0.232710  0.763015  0.004275\n",
       "7   0.000003  0.000870  0.999127\n",
       "8   0.000400  0.789072  0.210528\n",
       "9   0.074304  0.242442  0.683254\n",
       "10  0.708938  0.287579  0.003482"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708938</td>\n",
       "      <td>0.287579</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.076618</td>\n",
       "      <td>0.923344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221079</td>\n",
       "      <td>0.703894</td>\n",
       "      <td>0.075027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745596</td>\n",
       "      <td>0.095790</td>\n",
       "      <td>0.158615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.799730</td>\n",
       "      <td>0.197915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.279098</td>\n",
       "      <td>0.714269</td>\n",
       "      <td>0.006633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.232710</td>\n",
       "      <td>0.763015</td>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.999127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.789072</td>\n",
       "      <td>0.210528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074304</td>\n",
       "      <td>0.242442</td>\n",
       "      <td>0.683254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.708938</td>\n",
       "      <td>0.287579</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
